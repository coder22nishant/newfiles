{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Admin\\\\Desktop\\\\Training\\\\PGAA001\\\\LogReg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bankloan.sas7bdat',\n",
       " 'cust_new.csv',\n",
       " 'Data.csv',\n",
       " 'Logistic-Copy1.html',\n",
       " 'Logistic-Copy1.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()  # CSV , .sas7bdat- SAS data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_sas(\"bankloan.sas7bdat\", encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>debtinc</th>\n",
       "      <th>creddebt</th>\n",
       "      <th>othdebt</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>11.359392</td>\n",
       "      <td>5.008608</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.362202</td>\n",
       "      <td>4.000798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.856075</td>\n",
       "      <td>2.168925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.658720</td>\n",
       "      <td>0.821280</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.787436</td>\n",
       "      <td>3.056564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.239328</td>\n",
       "      <td>0.624672</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.026708</td>\n",
       "      <td>2.585292</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>847</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.722304</td>\n",
       "      <td>3.381696</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>848</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.417456</td>\n",
       "      <td>1.454544</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>849</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.899130</td>\n",
       "      <td>4.389870</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   ed  employ  address  income  debtinc   creddebt   othdebt  default\n",
       "0    41.0  3.0    17.0     12.0   176.0      9.3  11.359392  5.008608      1.0\n",
       "1    27.0  1.0    10.0      6.0    31.0     17.3   1.362202  4.000798      0.0\n",
       "2    40.0  1.0    15.0     14.0    55.0      5.5   0.856075  2.168925      0.0\n",
       "3    41.0  1.0    15.0     14.0   120.0      2.9   2.658720  0.821280      0.0\n",
       "4    24.0  2.0     2.0      0.0    28.0     17.3   1.787436  3.056564      1.0\n",
       "..    ...  ...     ...      ...     ...      ...        ...       ...      ...\n",
       "845  34.0  1.0    12.0     15.0    32.0      2.7   0.239328  0.624672      NaN\n",
       "846  32.0  2.0    12.0     11.0   116.0      5.7   4.026708  2.585292      NaN\n",
       "847  48.0  1.0    13.0     11.0    38.0     10.8   0.722304  3.381696      NaN\n",
       "848  35.0  2.0     1.0     11.0    24.0      7.8   0.417456  1.454544      NaN\n",
       "849  37.0  1.0    20.0     13.0    41.0     12.9   0.899130  4.389870      NaN\n",
       "\n",
       "[850 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "ed            0\n",
       "employ        0\n",
       "address       0\n",
       "income        0\n",
       "debtinc       0\n",
       "creddebt      0\n",
       "othdebt       0\n",
       "default     150\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=df.default.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    517\n",
       "1.0    183\n",
       "NaN    150\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7385714285714285"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]/(d[0]+d[1]) # 73% non fraud , 27% Fraud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"default\"].isnull().sum() # count of missing where there is no "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_customer=df[df.default.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_customer.to_csv(\"cust_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>debtinc</th>\n",
       "      <th>creddebt</th>\n",
       "      <th>othdebt</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.544128</td>\n",
       "      <td>2.943872</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>701</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>1.316574</td>\n",
       "      <td>1.392426</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>702</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.880700</td>\n",
       "      <td>0.729300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>703</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>704</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.866736</td>\n",
       "      <td>1.005264</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.239328</td>\n",
       "      <td>0.624672</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.026708</td>\n",
       "      <td>2.585292</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>847</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.722304</td>\n",
       "      <td>3.381696</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>848</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.417456</td>\n",
       "      <td>1.454544</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>849</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.899130</td>\n",
       "      <td>4.389870</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   ed  employ  address  income  debtinc  creddebt   othdebt  default\n",
       "700  36.0  1.0    16.0     13.0    32.0     10.9  0.544128  2.943872      NaN\n",
       "701  50.0  1.0     6.0     27.0    21.0     12.9  1.316574  1.392426      NaN\n",
       "702  40.0  1.0     9.0      9.0    33.0     17.0  4.880700  0.729300      NaN\n",
       "703  31.0  1.0     5.0      7.0    23.0      2.0  0.046000  0.414000      NaN\n",
       "704  29.0  1.0     4.0      0.0    24.0      7.8  0.866736  1.005264      NaN\n",
       "..    ...  ...     ...      ...     ...      ...       ...       ...      ...\n",
       "845  34.0  1.0    12.0     15.0    32.0      2.7  0.239328  0.624672      NaN\n",
       "846  32.0  2.0    12.0     11.0   116.0      5.7  4.026708  2.585292      NaN\n",
       "847  48.0  1.0    13.0     11.0    38.0     10.8  0.722304  3.381696      NaN\n",
       "848  35.0  2.0     1.0     11.0    24.0      7.8  0.417456  1.454544      NaN\n",
       "849  37.0  1.0    20.0     13.0    41.0     12.9  0.899130  4.389870      NaN\n",
       "\n",
       "[150 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df[df.default.notnull()]  # Historical data for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>debtinc</th>\n",
       "      <th>creddebt</th>\n",
       "      <th>othdebt</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>11.359392</td>\n",
       "      <td>5.008608</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.362202</td>\n",
       "      <td>4.000798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.856075</td>\n",
       "      <td>2.168925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.658720</td>\n",
       "      <td>0.821280</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.787436</td>\n",
       "      <td>3.056564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.262062</td>\n",
       "      <td>0.979938</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>696</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.369495</td>\n",
       "      <td>2.045505</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>697</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.491264</td>\n",
       "      <td>1.940736</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>698</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.302608</td>\n",
       "      <td>4.165392</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>699</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2.994684</td>\n",
       "      <td>3.473316</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age   ed  employ  address  income  debtinc   creddebt   othdebt  default\n",
       "0    41.0  3.0    17.0     12.0   176.0      9.3  11.359392  5.008608      1.0\n",
       "1    27.0  1.0    10.0      6.0    31.0     17.3   1.362202  4.000798      0.0\n",
       "2    40.0  1.0    15.0     14.0    55.0      5.5   0.856075  2.168925      0.0\n",
       "3    41.0  1.0    15.0     14.0   120.0      2.9   2.658720  0.821280      0.0\n",
       "4    24.0  2.0     2.0      0.0    28.0     17.3   1.787436  3.056564      1.0\n",
       "..    ...  ...     ...      ...     ...      ...        ...       ...      ...\n",
       "695  36.0  2.0     6.0     15.0    27.0      4.6   0.262062  0.979938      1.0\n",
       "696  29.0  2.0     6.0      4.0    21.0     11.5   0.369495  2.045505      0.0\n",
       "697  33.0  1.0    15.0      3.0    32.0      7.6   0.491264  1.940736      0.0\n",
       "698  45.0  1.0    19.0     22.0    77.0      8.4   2.302608  4.165392      0.0\n",
       "699  37.0  1.0    12.0     14.0    44.0     14.7   2.994684  3.473316      0.0\n",
       "\n",
       "[700 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate , bivariate , Multivariate --- You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(columns=[\"default\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'ed', 'employ', 'address', 'income', 'debtinc', 'creddebt',\n",
       "       'othdebt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)  # Model train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.score(x_test, y_test)  # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.predict(x_train)  # by default cut off of p >=0.5  ( if p >=0.5, 1 ,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prob_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.072658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.044470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.010625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.023667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.711152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.683588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521</td>\n",
       "      <td>0.125353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522</td>\n",
       "      <td>0.006138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523</td>\n",
       "      <td>0.446496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524</td>\n",
       "      <td>0.093097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prob_1\n",
       "0    0.072658\n",
       "1    0.044470\n",
       "2    0.010625\n",
       "3    0.023667\n",
       "4    0.711152\n",
       "..        ...\n",
       "520  0.683588\n",
       "521  0.125353\n",
       "522  0.006138\n",
       "523  0.446496\n",
       "524  0.093097\n",
       "\n",
       "[525 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(logisticRegr.predict_proba(x_train)[:,1], columns=[\"Prob_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.072658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.044470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.010625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.023667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.711152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.683588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521</td>\n",
       "      <td>0.125353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522</td>\n",
       "      <td>0.006138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523</td>\n",
       "      <td>0.446496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524</td>\n",
       "      <td>0.093097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted_Prob\n",
       "0          0.072658\n",
       "1          0.044470\n",
       "2          0.010625\n",
       "3          0.023667\n",
       "4          0.711152\n",
       "..              ...\n",
       "520        0.683588\n",
       "521        0.125353\n",
       "522        0.006138\n",
       "523        0.446496\n",
       "524        0.093097\n",
       "\n",
       "[525 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(logisticRegr.predict_proba(x_train)[:,1], columns=[\"Predicted_Prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_train=logisticRegr.predict(x_train) # Its predicting 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_test=logisticRegr.predict(x_test) # Its predicting 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.91      0.87       385\n",
      "         1.0       0.67      0.49      0.56       140\n",
      "\n",
      "    accuracy                           0.80       525\n",
      "   macro avg       0.75      0.70      0.72       525\n",
      "weighted avg       0.79      0.80      0.79       525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_predicted_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91       132\n",
      "         1.0       0.78      0.58      0.67        43\n",
      "\n",
      "    accuracy                           0.86       175\n",
      "   macro avg       0.83      0.76      0.79       175\n",
      "weighted avg       0.85      0.86      0.85       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predicted_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use score method to get accuracy of model\n",
    "# score = logisticRegr.score(x_train, y_train)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[352  33]\n",
      " [ 72  68]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_train, y_predicted_train) # metrics.confusion_matrix(Actual, predicted)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125   7]\n",
      " [ 18  25]]\n"
     ]
    }
   ],
   "source": [
    "cmtest = metrics.confusion_matrix(y_test, y_predicted_test) # metrics.confusion_matrix(Actual, predicted)\n",
    "print(cmtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "# all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "# plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1=x_train.copy()\n",
    "x_test1=x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1[\"Default\"]=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1[\"Prob_default\"]=logisticRegr.predict_proba(x_train)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1[\"Pred_default\"]=y_predicted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1[\"Default\"]=y_test\n",
    "x_test1[\"Prob_default\"]=logisticRegr.predict_proba(x_test)[:,1]\n",
    "x_test1[\"Pred_default\"]=y_predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1.to_excel(\"x_train1.xlsx\")\n",
    "x_test1.to_excel(\"x_test1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_decile(X,y, trained_model):\n",
    "    X_1=X.copy()\n",
    "    y_1=y.copy()\n",
    "    y_pred=trained_model.predict(X_1)\n",
    "    X_1[\"Prob_event\"]=trained_model.predict_proba(X_1)[:,1]\n",
    "    X_1[\"Y_actual\"]=y_1\n",
    "    X_1[\"Y_pred\"]=y_pred\n",
    "    X_1[\"Rank\"]=pd.qcut(X_1[\"Prob_event\"],10, labels=np.arange(0,10,1))\n",
    "    X_1[\"numb\"]=10\n",
    "    X_1[\"Decile\"]=X_1[\"numb\"]-X_1[\"Rank\"].astype(\"int\")\n",
    "    profile=pd.DataFrame(X_1.groupby(\"Decile\")\\\n",
    "                        .apply(lambda x: pd.Series({\n",
    "        \"min_score\": x[\"Prob_event\"].min(),\n",
    "        \"max_score\": x[\"Prob_event\"].max(),\n",
    "        \"Bad\":x[\"Y_actual\"].sum(),\n",
    "        \"Good\":x[\"Y_actual\"].count()-x[\"Y_actual\"].sum(),\n",
    "        \"Total\":x[\"Y_actual\"].count() })))\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_train=profile_decile(x_train, y_train, logisticRegr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>Bad</th>\n",
       "      <th>Good</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.635597</td>\n",
       "      <td>0.999153</td>\n",
       "      <td>42.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.487316</td>\n",
       "      <td>0.635544</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.385353</td>\n",
       "      <td>0.486043</td>\n",
       "      <td>21.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.288781</td>\n",
       "      <td>0.385267</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.197635</td>\n",
       "      <td>0.285965</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.133678</td>\n",
       "      <td>0.196512</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074889</td>\n",
       "      <td>0.132866</td>\n",
       "      <td>6.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.035296</td>\n",
       "      <td>0.074519</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        min_score  max_score   Bad  Good  Total\n",
       "Decile                                         \n",
       "1        0.635597   0.999153  42.0  11.0   53.0\n",
       "2        0.487316   0.635544  28.0  24.0   52.0\n",
       "3        0.385353   0.486043  21.0  32.0   53.0\n",
       "4        0.288781   0.385267  23.0  29.0   52.0\n",
       "5        0.197635   0.285965  10.0  42.0   52.0\n",
       "6        0.133678   0.196512   5.0  48.0   53.0\n",
       "7        0.074889   0.132866   6.0  46.0   52.0\n",
       "8        0.035296   0.074519   4.0  49.0   53.0\n",
       "9        0.010625   0.033626   1.0  51.0   52.0\n",
       "10       0.000330   0.010280   0.0  53.0   53.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_train.to_csv(\"profile_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_test=profile_decile(x_test, y_test, logisticRegr)\n",
    "profile_test.to_csv(\"profile_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs=logisticRegr.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoy0lEQVR4nO3dd3zV9dn/8ddFmGGTsEMIeyNoBAdFFEQUlWqpRa2tHTdd/rxrbxXqqqPD27Zqe9dqcVC1dRVFUbG0WgVUUKIiI4KyCaDsTSDj+v1xTvQYkpCQfM98Px8PHo/zPeeTnOsLIdf5rOtj7o6IiKSuerEOQEREYkuJQEQkxSkRiIikOCUCEZEUp0QgIpLilAhERFKcEoGISIpTIpCkYmbrzOyQme03s0/N7K9m1qxcm9PM7D9mts/M9pjZi2bWv1ybFmZ2r5ltCH+vVeHrzEre18zsajNbZmYHzKzAzP5hZoOCvF+RuqBEIMnoAndvBgwBhgI/L3vBzE4F/gW8AHQCugEfAm+ZWfdwm4bAa8AAYBzQAjgN2AEMq+Q9/wD8N3A10AboDTwPjK9p8GZWv6ZfI1Ibpp3FkkzMbB3wfXd/NXx9FzDA3ceHr+cDS939x+W+7hVgm7t/y8y+D/wK6OHu+6vxnr2AFcCp7v5uJW3eAP7m7g+Fr68MxzkifO3AVcBPgfrAHGC/u18b8T1eAOa6+91m1gn4P2AksB+4x93/eOy/IZGjqUcgScvMsoBzgVXh63RCn+z/UUHzZ4Czw4/HAP+sThIIGw0UVJYEauCrwHCgP/AE8A0zMwAzaw2MBZ4ys3rAi4R6Mp3D7/9TMzunlu8vKUqJQJLR82a2D9gIbAV+EX6+DaGf+S0VfM0WoGz8P6OSNpWpafvK/Mbdd7r7IWA+4MBXwq9NBBa4+2bgZKCtu9/u7kfcfQ3wIDCpDmKQFKREIMnoq+7eHBgF9OWLX/C7gFKgYwVf0xHYHn68o5I2lalp+8psLHvgoTHbp4BLw09dBvw9/Lgr0MnMdpf9AW4A2tdBDJKClAgkabn7XOCvwO/C1weABcDXK2h+CaEJYoBXgXPMrGk13+o1IMvMcqtocwBIj7juUFHI5a6fBCaaWVdCQ0bPhp/fCKx191YRf5q7+3nVjFfkS5QIJNndC5xtZkPC11OBb4eXejY3s9Zm9kvgVOC2cJvHCf2yfdbM+ppZPTPLMLMbzOyoX7bu/gnwZ+BJMxtlZg3NrLGZTTKzqeFmi4GLzSzdzHoC3ztW4O7+AbANeAiY4+67wy+9C+w1sylm1sTM0sxsoJmdXNO/HBFQIpAk5+7bgMeAm8PXbwLnABcTGtdfT2iJ6YjwL3Tc/TChCeMVwL+BvYR++WYC71TyVlcDfwLuA3YDq4GLCE3qAtwDHAE+Ax7li2GeY3kyHMsTEfdUAlxAaHnsWkJDWg8BLav5PUW+RMtHRURSnHoEIiIpTolARCTFKRGIiKQ4JQIRkRSXcMWtMjMzPScnJ9ZhiIgklPfee2+7u7et6LWESwQ5OTnk5eXFOgwRkYRiZusre01DQyIiKU6JQEQkxSkRiIikuISbIxARSXVFRUUUFBRQWFh41GuNGzcmKyuLBg0aVPv7KRGIiCSYgoICmjdvTk5ODuGziwBwd3bs2EFBQQHdunWr9vcLbGjIzB4xs61mtqyS183M/hg+FHyJmZ0YVCwiIsmksLCQjIyMLyUBADMjIyOjwp5CVYKcI/groYO/K3Mu0Cv8ZzJwf4CxiIgklfJJ4FjPVyWwoSF3n2dmOVU0mQA8Fj6JaaGZtTKzju5eF0f+iUiqyZsOS2fEOopAlLhTVFJK46whcO6ddf79Y7lqqDMRR/MBBeHnjmJmk80sz8zytm3bFpXgRCTBLJ0Bny6NdRR1bs+hIpYU7Objz/bhRx1iVzdiOVlcUf+lwrt092nANIDc3FwdoCCSCKL9Cf3TpdBhEHzn5ei9Z4D2HCriN7M/4qmVG8nJSOfOrw3Gumd8/rq7VzgMdDxnzMQyERQAXSKus4DNMYpFROpKWQJY/2bouuuI6Lxvh0EwaGJ03itgJaXO1+5/mzXb9vODM7pzzZjeNG6Q9vnrjRs3ZseOHUdNGJetGmrcuHGN3i+WiWAWcJWZPUXoYO49mh8QSUDlP/lHJoBBEyH3O7GJKwHtOnCEVukNSKtnXDu2D51aNWZwVquj2mVlZVFQUEBFQ+Vl+whqIrBEYGZPAqOATDMrAH4BNABw9weA2cB5wCrgIKCfFpFEVDY232FQ6FoJoMbcnecXb+K2F/OZMq4vlw7LZtzADpW2b9CgQY32CRxLkKuGLj3G6w78JKj3FxGiM06fZGPz0bZ59yFunLmU11duY2h2K3K7to56DNpZLJIMKvuFH41x+iQam4+2FxZv4saZyygpdW45vz/fPi2HtHo13wdQW0oEIsmg/PBMGQ3TxLWWTRowpEsrfnPxILq0SY9ZHEoEIvHkeIdyNDyTEIpLSnn4zbUUlZRy1Vm9GNWnHWf0bntcu4HrkhKBSLRU55f88Q7laHgm7uVv3suUZ5ewdNMexg/u+Pk+gFgnAVAiEImeyoZvImkoJ+kcLi7hT/9Zxf1vrKZVegP+fPmJnDuwQ1wkgDJKBCJBqOjTv4ZvUtK67Qd5YO5qLhzSiZvH96d104axDukoSgQidamqXbUavkkZBw4X8+/8z/jq0M706dCc1342iuyM2E0GH4sSgUhdqCgBaIgnJc3/ZBs/f24pm3YfYmDnFvRs1zyukwAoEYjUjbLxfyWAlLXnYBG/mp3PM3kFdM9sytOTT6Vnu+axDqtalAhEKlLTZZwa/09pJaXO1x54m7XbD/DjUT24enSvLxWJi3dKBJLYgiqhUNNlnBr/T0k7DxyhVZNQkbjrzulD51ZNGNi5ZazDqjElAkls1VmSeTw0xCNVcHeee38Tt78UKhJ32fBszhlQeZG4eKdEIIknshegIRmJsoJdB7lh5jLmfbyNk7q2Zli3NrEOqdaUCCSx5E2Hl34aetx1hIZkJKpmflDATTOX4cBtFw7gilO6Ui8GReLqmhKBxK+Kxv/Lxu7Pv1fDNhJ1bZo24qScNvz6ooFktY7vJaE1oUQg8aui8X+N3UsUFZWU8uD8NRSXOFeP7sUZvdsysldmXJWHqAtKBBIfVJJB4syyTXuY8uwSlm/eywUndIqrInF1TYlA4kNFn/41/i8xUFhUwh9f+4S/zFtD6/SGPPDNExk3sGOswwqUEoHED336lziwfsdBHpy/houHduam8f1pmd4g1iEFTolAglXdDV9B7AUQqaYDh4uZs/xTLj4xiz4dmvOf/xkV0xPDok2JQOpe5C//6u7Q1TCQxMjcj7dxw3NL2bznEIOzWtKzXfOUSgKgRCB1pbJf/lrlI3Fq14Ej3PFyPs+9v4kebZvyjx8kTpG4uqZEIHUjcrJXv/wlzpUViVu/4yBXndmTq87qmVBF4uqaEoHUXt70UC+g6whN9kpc27H/MK3TG5JWz5g6ri+dWzdhQKfEKxJX1+rFOgBJcJElHzTGL3HK3XkmbyNn/u4Nnly0AYCxAzooCYSpRyC1UzYvoJIPEqc27jzIDTOXMv+T7QzLacOp3TNiHVLcUSKQmitf/bPrCCUBiUvPvV/ATc8vw4A7vjqQy4dlJ0WRuLqmRCA1FzkxrGWfEscymzViWLc2/OqiQXRu1STW4cQtJQI5PtoFLHGoqKSUv8xdTUkp/PeYXozs3ZaRvdvGOqy4p0Qgx1Z+d7B2AUscWrZpD9fNWMJHW/YyYcgXReLk2JQIpGJV7Q7WcJDEkcKiEu599RMenL+GNk0b8pcrTkroYyNjIdBEYGbjgD8AacBD7n5nudezgUeBVuE2U919dpAxSTVpg5gkiA07D/Lwm2uYeGIWN5zXLyWKxNW1wBKBmaUB9wFnAwXAIjOb5e75Ec1uAp5x9/vNrD8wG8gJKiapIc0DSJzaV1jEP5d9ytdzu9C7fXNev3ZUUp0YFm1B9giGAavcfQ2AmT0FTAAiE4EDLcKPWwKbA4xHRJLA6yu2cuPMpXy6t5Ch2a3o2a65kkAtBZkIOgMbI64LgOHl2twK/MvM/h/QFBhT0Tcys8nAZIDs7Ow6D1TCyu8P0ISwxJGdB45wx0v5zPxgE73aNWPGj05L2SJxdS3IEhMVTdd7uetLgb+6exZwHvC4mR0Vk7tPc/dcd89t21ZLwQJTNi8AmhCWuFJS6ky8/21e/HAzV4/uxUtXj+DE7NaxDitpBNkjKAC6RFxncfTQz/eAcQDuvsDMGgOZwNYA45LyynoCOiNY4sy2fYfJaBoqEnfDef3o3LoJ/Tq2OPYXSo0E2SNYBPQys25m1hCYBMwq12YDMBrAzPoBjYFtAcYk5ZUVjVv/pnoBEjfcnacXbeCs37/BE++GisSN6d9eSSAggfUI3L3YzK4C5hBaGvqIuy83s9uBPHefBfwP8KCZXUNo2OhKdy8/fCRBUtE4iTMbdhxk6nNLeHv1DoZ3a8OInpmxDinpBbqPILwnYHa5526JeJwPnB5kDFINKhoncWLGewXc/Pwy0uoZv7poIJeerCJx0aCdxamq/LyASBxo36IRp/XI4JcXDaRjSxWJixYlglQUeZhM2a5hkRg4UlzK/W+sptSda87uzVd6teUrvbQyMNqUCFKR5gUkDny4cTfXz1jCys/2cfHQzioSF0NKBKlK8wISI4eOlHD3v1fy8Jtrade8MQ99K5cx/dvHOqyUpkQgIlG1cddBHn17PZOGZTP13L60aKwicbGmRJBKNEEsMbI3XCTuknCRuDeuG0UnnRgWN5QIUklkEtAEsUTJf1Z8xg3PLWPrvkJOzG5Nz3bNlATijBJBqsibHto93HWESkhIVOzYf5jbX8rnhcWb6dO+OQ9ccRI92zWLdVhSASWCVFG2Ukg9AYmCklLn6w8sYOOug1wzpjc/GtWDhvWDrGgjtaFEkEq0UkgCtnVfIZlNG5FWz7hxfD+yWqfTp4NKRcc7pehUUDYsJBKQ0lLn7++s56zfzeXv4SJxo/u1VxJIEOoRJLOyVUJlSUDDQhKAddsPMPW5JSxcs5PTemRwhnYGJxwlgmRWtkpIh89LQJ7J28jNzy+jYVo97rx4EN84uYt2BycgJYJkpVVCEgWdWzVhZO+23DFhIB1aNo51OHKclAiSlVYJSQAOF5fw59dX4+78bGwfTu+Zyek6LyDhKREkm8jdw1olJHXogw27mPLsEj7+bD9fOzFLReKSiBJBstHuYaljB48U8/t/fcwjb62lQ4vGPHJlLmf1VZG4ZKJEkEw0LyAB2LTrEI8vXM/lw7OZMq4vzVUkLukoESQTzQtIHdlzqIhXlm5h0rBserVvztzrRunEsCSmRJBsNC8gtfSv5Z9y0/PL2HHgCLk5bejZrpmSQJLTzuJkod3DUkvb9x/mqifeZ/Lj79GmaUNm/vg0FYlLEeoRJDrtHpY6UFLqTLz/bTbvLuTasb35wRk9aJCmz4mpQokgkVV0CL2GhaQGPttbSNtmoSJxv7hgAFmtm9CrveoDpRolgkSmQ+jlOJWWOn9/dwP/+8oKpozrwxWn5nBm33axDktiRIkgUUUuFVUSkBpYs20/U59byrtrdzKiZyaj+igBpDolgkRQNg8QSXMCchyeXrSBW15YTqP69bhr4mC+flKWdgeLEkFCqOjAec0JyHHIap3OqD6hInHtWqhInIQoEcQ77RaWWjhcXML/vbYKgGvPUZE4qZgSQTyLXBWkISCpoffW7+T6GUtYve0Al+SqSJxUTokgHpXfG6BVQVIDBw4X89s5K3l0wTo6tWzCo98dxhm9dWqYVC7QHSNmNs7MVprZKjObWkmbS8ws38yWm9kTQcaTMCLLSCsJSA1t3n2IJ97dwLdO6cqca0YqCcgxBdYjMLM04D7gbKAAWGRms9w9P6JNL+DnwOnuvsvMtI6tTIdBmhOQattzsIiXl27hsuGhInHzrz+T9poMlmoKcmhoGLDK3dcAmNlTwAQgP6LNfwH3ufsuAHffGmA8Iknpn8s+5eYXlrHzwBGGd29Dj7bNlASkRoIcGuoMbIy4Lgg/F6k30NvM3jKzhWY2rqJvZGaTzSzPzPK2bdsWULgiiWXrvkJ+/Pf3+OHf3qNts0a88JPT6dFWReKk5oLsEVS0PMEreP9ewCggC5hvZgPdffeXvsh9GjANIDc3t/z3EEk5JaXOJQ8sYPOeQq47pw+TR3ZXkTg5bkEmggKgS8R1FrC5gjYL3b0IWGtmKwklhkUBxiWSsLbsOUT75o1DReIuHECX1ukqFS21FuRHiEVALzPrZmYNgUnArHJtngfOBDCzTEJDRWsCjEkkIZWWOn99ay2jfz+Xv72zHoAz+7RTEpA6EViPwN2LzewqYA6QBjzi7svN7HYgz91nhV8ba2b5QAlwnbvvCCqmuFNRDSE4upyEpLRVW/cz9dkl5K3fxcjebTlLVUKljpl7Yg255+bmel5eXqzDqL3yZwmUpzpCAjz17gZumbWcJg3SuOX8/lx8YmftDpbjYmbvuXtuRa9pZ3Gs6CwBqYbsjHTG9GvHbRcOpG3zRrEOR5KUEkEs6SwBKaewqIQ/vvYJANeP68tpPTI5rYeKxEmwtN5MJE7krdvJeX+cz5/fWM3OA0dItGFbSVzqEYjE2P7Dxfz2nyt4bOF6OrdqwmPfHcZI1QeSKFIiEImxT/cc4qlFG/n2qTlcd04fmjbSf0uJLv3EicTArgNHeGnpFq44pSs924WKxOnEMImVGs8RmFmamV0eRDApIW86TB8f2isgKcfdmb10C2ffM5fbZi1n9bb9AEoCElOV9gjMrAXwE0KF4mYB/wauAq4FFgN/j0J8yaP8YTNlZw5Lyti6t5CbX1jGnOWfMahzSx777nAViZO4UNXQ0OPALmAB8H3gOqAhMMHdFwcfWpKJPGxGm8VSTkmp8/W/LODTPYX8/Ny+fG9EN+qrSJzEiaoSQXd3HwRgZg8B24Fsd98XlciSRVlPoKxshA6bSSmbdx+iQ4tQkbjbJwykS+smdFcvQOJMVR9JisoeuHsJsFZJ4DhEJgENBaWMklJnerkicWf0bqskIHGpqh7BCWa2ly/OFWgSce3u3iLw6JKFegIpZdXWfVw/Ywnvb9jNqD5tGd2vfaxDEqlSpYnA3dOiGUhSypsemhyuqKicJKUn3tnArbOW07RRGvd84wS+OkRF4iT+VbVqqDHwQ6AnsIRQGeniaAWW0MqvENKQUMrIyUxn7ID23HrhADKbqUicJIaqhoYeJTRPMB84DxgA/Hc0gkp4WiGUMgqLSrjn1Y8xjKnnqkicJKaqEkH/iFVDDwPvRiekJKF5gaT3zpodTH1uKWu3H+Dy4dm4u4aBJCFVlQgiVw0V6wf8GCJPG9MJY0ltX2ER//vPFfxt4Qay26TzxPeHc1pP9QIkcVWVCIaEVwlBaKWQVg1VJXKZqJaKJrXP9h5mxnsFfH9EN342tjfpDVWySxJbVT/BH7r70KhFkgw0HJS0dh44wstLNnPFqTn0bNeM+defpRPDJGlUlQh0KoakPHfnpSVbuHXWcvYWFnF6z0y6t22mJCBJpapE0M7MflbZi+5+dwDxiMSNz/YWcuPMZbz60WcMzmrJ3ycO185gSUpVJYI0oBlf7CwWSRklpc4l4SJxN57Xj++cnqMicZK0qkoEW9z99qhFkqjKF5WThFaw6yAdWzYhrZ5xx4SBZLdJJyezaazDEglUVR9x1BM4lrzp8NJPQzuItVIooZWUOg/NX8OYu+fyt4WhInEje7dVEpCUUFWPYHTUokhUZfsGzr9Xu4cT2MpP93H9s0v4cONuRvdtx9gBKhInqaWqonM7oxlIwuo6Qkkggf1t4Xpue3E5zRs34A+ThnDhCZ20O1hSjnbCSEoqKwfRs10zzhvUkVvO70+GisRJilIiqCmVkkhoh46UcPe/V1KvnvHzc/txSvcMTumeEeuwRGJK6+FqqmyFEGiCOMEsWL2DcX+Yx4Pz13LwcAnu2jMpAuoRHB+VkkgoewuL+M3sFTz57ga6ZqTzxH8NV6lokQhKBJL0tu49zPMfbGLyyO5cM6Y3TRrq8D2RSIEODZnZODNbaWarzGxqFe0mmpmbWW6Q8dRK3nSYPv6LYSGJazv2H+avb60FoGe7Zrw55UxuOK+fkoBIBQLrEZhZGnAfcDZQACwys1nunl+uXXPgauCdoGKpE5G7hzUvELfcnVkfbubWWcvZf7iYkb3b0r1tM60IEqlCkENDw4BV7r4GwMyeAiYA+eXa3QHcBVwbYCy1E3kIveYG4tbm3Ye46fll/GfFVoZ0acVdEwerSJxINQSZCDoDGyOuC4DhkQ3MbCjQxd1fMrNKE4GZTQYmA2RnZwcQ6jGULRdVTyBuFZeUMmnaQrbtO8zN5/fnytNySKunjWEi1RFkIqjof+Hn6/XMrB5wD3Dlsb6Ru08DpgHk5ubGZs2fdhDHpY07D9KpVRPqp9Xj1xcNIrtNOtkZ6bEOSyShBDlZXAB0ibjOAjZHXDcHBgJvmNk64BRgVlxPGEvcKC4pZdq81Yy5ey6PL1gHwIhemUoCIschyB7BIqCXmXUDNgGTgMvKXnT3PcDni7nN7A3gWnfPCzAmSQIfbdnLlGeXsKRgD2f3b8+5gzrGOiSRhBZYInD3YjO7CphD6JCbR9x9uZndDuS5+6yg3rtORU4US8w9vmAdt72YT8smDfjTZUMZP6ijisSJ1FKgG8rcfTYwu9xzt1TSdlSQsRw3TRTHhbIicb3bN+eCEzpx8/n9adO0YazDEkkK2llcHZoojpmDR4r53ZyPqZ9m3HBeP4Z3z2C4isSJ1CkVnatK2bCQxMRbq7Zzzr3zeOSttRwpLlWROJGAqEdQFQ0LxcSeQ0X8+uWPeDpvI90ym/LMD05lWLc2sQ5LJGkpERyLhoWibvv+w7y4ZDM/PKMHPx3Ti8YNVB9IJEhKBBIXtu07zIsfbua7I7rRo20z3pxyliaDRaJEiUBiyt15fvEmbnsxn4OHSzizbzu6ZTZVEhCJIiUCiZlNuw9x48ylvLFyGydmh4rEdctsGuuwRFKOEoHERKhI3AJ27D/CrRf054pTVSROJFaUCCpSdkC9Dqevcxt2HKRz61CRuDsvHkx2m3S6tFF9IJFY0j6CiugQmjpXXFLK/W+sZsw9c3ksXCTu9J6ZSgIicUA9gsrogPo6s3zzHqY8u4Rlm/ZyzoD2jFeROJG4okQggXr07XXc8VI+rdIbcv/lJ6pSqEgcUiKQQJQVievboTkThnTm5vP70SpdS0JF4pESQSRNEtfagcPF/HbOShqkGTeO768icSIJQJPFkTRJXCvzPt7G2Hvm8eiCdRSVuIrEiSQI9QjK0yRxje05WMQdL+cz470CurcNFYk7OUdF4kQShRKB1Nr2A4d5ZekWfjyqB1ePVpE4kUSjRCDHZeu+QmYt3sz3v9L98yJxrVUfSCQhKRFIjbg7z76/iTteyudQUQmj+7WnW2ZTJQGRBKZEINW2cedBbpi5lPmfbCe3a2vu/JqKxIkkAyWCMmXHUnYdEetI4lJxSSmXPriQXQeOcMeEAVw+vCv1VCROJCkoEUAoCbz009BjLRv9knXbD9ClTTr10+px18RQkbis1qoPJJJMtI8Avjib+Px7dSxlWFFJKfe9voqx98z7vEjcaT0ylQREkpB6BGV0NvHnlm3aw/UzlpC/ZS/jB3Xk/MGdYh2SiARIiUC+ZPpba/nlyx/RpmlDHvjmSYwb2CHWIYlIwJQIBPiiSNyATi25eGhnbhrfn5bpDWIdlohEgRJBitt/uJi7/rmChmn1uOn8/gzr1oZh3VQeQiSVaLI4hb2xcivn3DOPxxeux0FF4kRSlHoEKWjXgSPc8XI+z72/iZ7tmjHjh6dxUtfWsQ5LRGJEiSAF7Tp4hH8t/4yrz+rJT87qSaP6KhInksoCHRoys3FmttLMVpnZ1Ape/5mZ5ZvZEjN7zcy6BhlPhcp2FCe5rXsLmTZvNe5O97bNeGvKWfxsbB8lAREJLhGYWRpwH3Au0B+41Mz6l2v2AZDr7oOBGcBdQcVTqbLNZEm6o9jdeWbRRkbfPZff/+tj1u04CKAVQSLyuSCHhoYBq9x9DYCZPQVMAPLLGrj76xHtFwLfDDCeyiXpZrKNOw/y8+eW8uaq7Qzr1oY7Lx6kInEicpQgE0FnYGPEdQEwvIr23wNeqegFM5sMTAbIzs6uq/iSWlmRuN0Hi/jlVwdy2bBsFYkTkQoFmQgq+q1T4fpEM/smkAucUdHr7j4NmAaQm5urNY5VWLv9ANnhInG/nXgCXTPS6dSqSazDEpE4FuRkcQHQJeI6C9hcvpGZjQFuBC5098MBxvNledNh+vjQYfVJoKiklP977RPOuWcej769DoBTe2QoCYjIMQXZI1gE9DKzbsAmYBJwWWQDMxsK/AUY5+5bA4zlaEtnhJJAh0EJP1G8pGA3189YwopP93HBCZ24cIiKxIlI9QWWCNy92MyuAuYAacAj7r7czG4H8tx9FvBboBnwDzMD2ODuFwYV0+ciD6H5zsuBv12QHnlzLb98OZ+2zRvx4LdyObt/+1iHJCIJJtANZe4+G5hd7rlbIh6PCfL9K5UES0bLisQNzmrJN07uwtRz+9GyiZaEikjNpe7O4gRdMrqvsIg7X1lBo/pp3HJBf3Jz2pCboyJxInL8VHQugby+Yitj75nHk+9uoH6aqUiciNSJ1O0RJJCdB45w+4vLeX7xZnq3b8afLz+NodkqEicidUOJIAHsOVTEax9t5b9H9+InZ/akYX115ESk7igRxKlP9xTy/OJN/GBkd7plNuXNqWdpMlhEAqFEEGfcnacWbeTXL39EUWkp4wZ0ICezqZKAiARGiSCOrN9xgKnPLmXBmh2c0r0Nd148mBwViRORgCkRxIniklIue/Ad9hwq4tcXDWLSyV1UJE5EokKJIMZWb9tP13CRuN9fEioS17Gl6gOJSPRo+UmMHCku5d5XP2bcvfN4bMF6AE7pnqEkICJRl3o9gsg6QzGyeONupsxYwsrP9jFhSCe+OrRzzGIREUm9RBDjOkMPv7mWX72cT7vmjXn427mM7qcicSISW6mXCCAmdYbKisQN6dKSScOymXpuX1o01pJQEYm91EwEUbS3sIjfzF5B4wb1+MUFAzipaxtO6qoicSISPzRZHKBX8z/j7Lvn8vSiDTSsX09F4kQkLqlHEIAd+w9z24v5zPpwM307NGfaFbmc0KVVrMMSEalQaiWCKK0Y2ldYzOsrt3LNmN78aFQPFYkTkbiWWokgwBVDm3cfYuYHm/jxqB7kZDblralnaTJYRBJCaiUCqPMVQ6WlzhPvbuDOV1ZQUuqMH9SRnMymSgIikjBSLxHUobXbDzD12SW8s3Ynp/fM4DcXDSY7Iz3WYYmI1IgSwXEqLinlmw+9w97CIu762mC+npuFmYrEiUjiUSKooVVb95GT0ZT6afW45xtD6JqRTvsWjWMdlojIcdNylmo6XFzC3f/+mHH3zufRcJG4Yd3aKAmISMJLnR5BLZaOvr9hF1NmLOGTrfu5eGhnLlaROBFJIqmTCI5z6eiD89bw61c+omOLxkz/zsmc2addAMGJiMRO6iQCqNHS0dJSp14948Surbh8eDZTxvWluZaEikgSSq1EUA17DhXxq5fzadIgjdsmDFSROBFJeposjjBn+aecffdcnn1/E00b1VeROBFJCeoRANv3H+YXLyzn5aVb6N+xBY9ceTIDO7eMdVgiIlGhRADsLyxm/ifbuO6cPkwe2Z0GaeooiUjqSNlEsGn3IWa+X8BPzuxJTmZT3v75aJo1Stm/DhFJYYF+9DWzcWa20sxWmdnUCl5vZGZPh19/x8xygowHQquBHl+wjrF3z+W+11ezfsdBACUBEUlZgf32M7M04D7gbKAAWGRms9w9P6LZ94Bd7t7TzCYB/wt8I6iYDhWV8O1pC3l33U6+0iuTX180iC5tVCRORFJbkB+DhwGr3H0NgJk9BUwAIhPBBODW8OMZwJ/MzDyA5TqO89GWvazwvfx24mAmnqQicSIiEGwi6AxsjLguAIZX1sbdi81sD5ABbI9sZGaTgckA2dnZxxWMdRhMp/RCXj33DNqpPpCIyOeCTAQVfdwu/0m/Om1w92nANIDc3Nzj6y2ceycdjusLRUSSW5CTxQVAl4jrLGBzZW3MrD7QEtgZYEwiIlJOkIlgEdDLzLqZWUNgEjCrXJtZwLfDjycC/wlifkBERCoX2NBQeMz/KmAOkAY84u7Lzex2IM/dZwEPA4+b2SpCPYFJQcUjIiIVC3TxvLvPBmaXe+6WiMeFwNeDjEFERKqmWgoiIilOiUBEJMUpEYiIpDglAhGRFGeJtlrTzLYB64/zyzMpt2s5BeieU4PuOTXU5p67unvbil5IuERQG2aW5+65sY4jmnTPqUH3nBqCumcNDYmIpDglAhGRFJdqiWBarAOIAd1zatA9p4ZA7jml5ghERORoqdYjEBGRcpQIRERSXFImAjMbZ2YrzWyVmU2t4PVGZvZ0+PV3zCwnBmHWqWrc88/MLN/MlpjZa2bWNRZx1qVj3XNEu4lm5maW8EsNq3PPZnZJ+N96uZk9Ee0Y61o1frazzex1M/sg/PN9XizirCtm9oiZbTWzZZW8bmb2x/DfxxIzO7HWb+ruSfWHUMnr1UB3oCHwIdC/XJsfAw+EH08Cno513FG45zOB9PDjH6XCPYfbNQfmAQuB3FjHHYV/517AB0Dr8HW7WMcdhXueBvwo/Lg/sC7WcdfynkcCJwLLKnn9POAVQic8ngK8U9v3TMYewTBglbuvcfcjwFPAhHJtJgCPhh/PAEZbYp9kf8x7dvfX3f1g+HIhoRPjEll1/p0B7gDuAgqjGVxAqnPP/wXc5+67ANx9a5RjrGvVuWcHWoQft+TokxATirvPo+qTGicAj3nIQqCVmXWszXsmYyLoDGyMuC4IP1dhG3cvBvYAGVGJLhjVuedI3yP0iSKRHfOezWwo0MXdX4pmYAGqzr9zb6C3mb1lZgvNbFzUogtGde75VuCbZlZA6PyT/xed0GKmpv/fjynQg2lipKJP9uXXyFanTSKp9v2Y2TeBXOCMQCMKXpX3bGb1gHuAK6MVUBRU59+5PqHhoVGEen3zzWygu+8ONrTAVOeeLwX+6u6/N7NTCZ16ONDdS4MPLybq/PdXMvYICoAuEddZHN1V/LyNmdUn1J2sqisW76pzz5jZGOBG4EJ3Pxyl2IJyrHtuDgwE3jCzdYTGUmcl+IRxdX+2X3D3IndfC6wklBgSVXXu+XvAMwDuvgBoTKg4W7Kq1v/3mkjGRLAI6GVm3cysIaHJ4Fnl2swCvh1+PBH4j4dnYRLUMe85PEzyF0JJINHHjeEY9+zue9w9091z3D2H0LzIhe6eF5tw60R1frafJ7QwADPLJDRUtCaaQdax6tzzBmA0gJn1I5QItkU1yuiaBXwrvHroFGCPu2+pzTdMuqEhdy82s6uAOYRWHDzi7svN7HYgz91nAQ8T6j6uItQTmBS7iGuvmvf8W6AZ8I/wvPgGd78wZkHXUjXvOalU857nAGPNLB8oAa5z9x2xi7p2qnnP/wM8aGbXEBoiuTKRP9iZ2ZOEhvYyw/MevwAaALj7A4TmQc4DVgEHge/U+j0T+O9LRETqQDIODYmISA0oEYiIpDglAhGRFKdEICKS4pQIRERSnBKBSDWZWYmZLY74k2Nmo8xsT7jy5Udm9otw28jnV5jZ72Idv0hlkm4fgUiADrn7kMgnwiXM57v7+WbWFFhsZmW1jcqebwJ8YGYz3f2t6IYscmzqEYjUEXc/ALwH9Cj3/CFgMbUsDCYSFCUCkeprEjEsNLP8i2aWQaim0fJyz7cmVO9nXnTCFKkZDQ2JVN9RQ0NhXzGzD4BS4M5wCYRR4eeXAH3Cz38atUhFakCJQKT25rv7+ZU9b2a9gTfDcwSLoxybyDFpaEgkYO7+MfAbYEqsYxGpiBKBSHQ8AIw0s26xDkSkPFUfFRFJceoRiIikOCUCEZEUp0QgIpLilAhERFKcEoGISIpTIhARSXFKBCIiKe7/AzsRt+aKYXdbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train, probs)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reciver Operative Charactoristics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8471799628942487"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "AUC = roc_auc_score(y_train, probs)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An AUC score is a measure of the likelihood that the model that produced the\n",
    "#predictions will rank a randomly chosen positive example above a randomly chosen negative example.\n",
    "#Specifically, that the probability will be higher for a real event (class=1) than a real non-event \n",
    "#(class=0).\n",
    "#Naive Prediction. A naive prediction under ROC AUC is any constant probability. \n",
    "#If the same probability is predicted for every example, there is no discrimination between positive\n",
    "#and negative cases, therefore the model has no skill (AUC=0.5).\n",
    "\n",
    "#Insensitivity to Class Imbalance. ROC AUC is a summary on the models ability to correctly \n",
    "#discriminate a single example across different thresholds. As such, it is unconcerned with the\n",
    "#base likelihood of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p value, Accuracy, Recall, Precision, ks Values , F1 score, Confusion matrix,ROC, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump \n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogisticReg.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(logisticRegr, \"LogisticReg.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "log=load(\"LogisticReg.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=pd.read_excel(\"new.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59583266, 0.17607485])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.predict_proba(new)[:,1] # 0.288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_customer=pd.read_csv(\"cust_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'ed', 'employ', 'address', 'income', 'debtinc', 'creddebt',\n",
       "       'othdebt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_customer.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cust=df_new_customer.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cust[\"Prob_default\"]=logisticRegr.predict_proba(df_new_customer)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cust[\"New_Default\"]=np.where(new_cust[\"Prob_default\"]>=0.288780649066183,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    98\n",
       "1    52\n",
       "Name: New_Default, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cust.New_Default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'warn',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.get_params()  # Parameters which can help us to get better ans fast results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score train :  0.8\n",
      " Score test :  0.8514285714285714\n",
      "non Zero Weights/ var 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_pe = LogisticRegression(C=2, penalty=\"l2\")  # C = 1/ Lambda\n",
    "log_pe.fit(x_train, y_train)\n",
    "print( \" Score train : \", log_pe.score(x_train, y_train))\n",
    "print( \" Score test : \", log_pe.score(x_test, y_test))\n",
    "print(\"non Zero Weights/ var\", np.count_nonzero(log_pe.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Value of C is  0.01\n",
      "  Score train :  0.7961904761904762\n",
      " Score test :  0.8457142857142858\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  0.1\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8514285714285714\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  1\n",
      "  Score train :  0.8\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  2\n",
      "  Score train :  0.8\n",
      " Score test :  0.8514285714285714\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  5\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  10\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  20\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  50\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  100\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  200\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in [0.01,0.1,1,2,5,10,20,50,100,200]:\n",
    "    log_pe = LogisticRegression(C=i, penalty=\"l2\")  # C = 1/ Lambda\n",
    "    log_pe.fit(x_train, y_train)\n",
    "    \n",
    "    print( \" Value of C is \" , i )\n",
    "    print( \"  Score train : \",  log_pe.score(x_train, y_train))\n",
    "    print( \" Score test : \", log_pe.score(x_test, y_test))\n",
    "    print(\"non Zero Weights/ var\", np.count_nonzero(log_pe.coef_))\n",
    "    print( \"-------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Value of C is  0.01\n",
      "  Score train :  0.7771428571428571\n",
      " Score test :  0.8057142857142857\n",
      "non Zero Weights/ var 5\n",
      "-------------------------------------\n",
      " Value of C is  0.1\n",
      "  Score train :  0.8038095238095239\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 7\n",
      "-------------------------------------\n",
      " Value of C is  1\n",
      "  Score train :  0.8\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 7\n",
      "-------------------------------------\n",
      " Value of C is  2\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  5\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  10\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  20\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  50\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  100\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n",
      " Value of C is  200\n",
      "  Score train :  0.7980952380952381\n",
      " Score test :  0.8571428571428571\n",
      "non Zero Weights/ var 8\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in [0.01,0.1,1,2,5,10,20,50,100,200]:\n",
    "    log_pe = LogisticRegression(C=i, penalty=\"l1\")  # C = 1/ Lambda\n",
    "    log_pe.fit(x_train, y_train)\n",
    "    \n",
    "    print( \" Value of C is \" , i )\n",
    "    print( \"  Score train : \",  log_pe.score(x_train, y_train))\n",
    "    print( \" Score test : \", log_pe.score(x_test, y_test))\n",
    "    print(\"non Zero Weights/ var\", np.count_nonzero(log_pe.coef_))\n",
    "    print( \"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03268243,  0.03918493, -0.25906754, -0.09329361, -0.00554865,\n",
       "         0.05619814,  0.55832946,  0.08423051]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pe.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pe = LogisticRegression(C=0.01, penalty=\"l1\")  # C = 1/ Lambda\n",
    "log_pe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03988249,  0.        , -0.10751549, -0.00698621,  0.00753833,\n",
       "         0.08311477,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pe.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.777 , test Score 0.806 at C= 0.01 and Penalty = l1\n",
      "Train Score 0.804 , test Score 0.857 at C= 0.1 and Penalty = l1\n",
      "Train Score 0.8 , test Score 0.857 at C= 1 and Penalty = l1\n",
      "Train Score 0.798 , test Score 0.851 at C= 2 and Penalty = l1\n",
      "Train Score 0.798 , test Score 0.857 at C= 5 and Penalty = l1\n",
      "Train Score 0.798 , test Score 0.857 at C= 10 and Penalty = l1\n",
      "Train Score 0.798 , test Score 0.857 at C= 20 and Penalty = l1\n",
      "Train Score 0.798 , test Score 0.857 at C= 50 and Penalty = l1\n",
      "Train Score 0.798 , test Score 0.857 at C= 100 and Penalty = l1\n",
      "Train Score 0.798 , test Score 0.857 at C= 200 and Penalty = l1\n",
      "Train Score 0.796 , test Score 0.846 at C= 0.01 and Penalty = l2\n",
      "Train Score 0.798 , test Score 0.851 at C= 0.1 and Penalty = l2\n",
      "Train Score 0.8 , test Score 0.857 at C= 1 and Penalty = l2\n",
      "Train Score 0.8 , test Score 0.851 at C= 2 and Penalty = l2\n",
      "Train Score 0.798 , test Score 0.857 at C= 5 and Penalty = l2\n",
      "Train Score 0.798 , test Score 0.857 at C= 10 and Penalty = l2\n",
      "Train Score 0.798 , test Score 0.857 at C= 20 and Penalty = l2\n",
      "Train Score 0.798 , test Score 0.857 at C= 50 and Penalty = l2\n",
      "Train Score 0.798 , test Score 0.857 at C= 100 and Penalty = l2\n",
      "Train Score 0.798 , test Score 0.857 at C= 200 and Penalty = l2\n"
     ]
    }
   ],
   "source": [
    "for l in [\"l1\", \"l2\"]:\n",
    "    for i in [0.01,0.1,1,2,5,10,20,50,100,200]:\n",
    "        log_pe = LogisticRegression(C=i, penalty=l)  # C = 1/ Lambda\n",
    "        log_pe.fit(x_train, y_train)\n",
    "        print(\"Train Score {} , test Score {} at C= {} and Penalty = {}\".format(\n",
    "            round(log_pe.score(x_train, y_train),3),round(log_pe.score(x_test, y_test), 3), i, l ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search for Hyperparameters tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_cv=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"C\":[.01, .1,1,10,50,100,200], \n",
    "        \"penalty\":[\"l1\", \"l2\"]}\n",
    "\n",
    "\n",
    "log_cv_gsearch=GridSearchCV(Log_cv, param_grid=params, cv=10,\n",
    "                            n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 14 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:   23.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 50, 100, 200],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_gsearch.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7961904761904762"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cv_gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_log=LogisticRegression(C=0.1, penalty=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_log.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7980952380952381"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_log.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8514285714285714"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_log.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "logreg_SGD = SGDClassifier(loss=\"log\",max_iter=1000, early_stopping=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=True, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_SGD.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7561904761904762"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_SGD.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7657142857142857"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_SGD.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------Logistic Regression ends here -------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.779\n",
      "[0.73239437 0.77464789 0.76056338 0.74285714 0.81428571 0.84285714\n",
      " 0.72857143 0.79710145 0.85507246 0.73913043]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "#import cross validation score model from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#create model selection object with number of splits\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "\n",
    "#creat a logistic regression model with SGD\n",
    "modelCV = SGDClassifier(loss=\"log\", tol=0.01,eta0=1.0,learning_rate=\"adaptive\", max_iter=1000, early_stopping=True,random_state=42)\n",
    "\n",
    "#call cross_val_score\n",
    "results = model_selection.cross_val_score(modelCV, x, y, cv=10 , scoring='accuracy')\n",
    "print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logreg_SGD = SGDClassifier(loss='log',random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             \"tol\":[0.0001, 0.001, 0.01, 0.1, 1],\n",
    "             \"eta0\":[0.2,0.5,1.0,1.5,2.0,2.5,3.0],\n",
    "             \"learning_rate\":[\"adaptive\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 245 candidates, totalling 735 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:561: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done 735 out of 735 | elapsed:   24.0s finished\n"
     ]
    }
   ],
   "source": [
    "# ignore the deprecation warning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "#create grid search object\n",
    "grid_search = GridSearchCV(logreg_SGD, param_grid=param_grid, verbose=True)\n",
    "\n",
    "grid_search.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'eta0': 0.2, 'learning_rate': 'adaptive', 'tol': 1}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7923809523809524"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
